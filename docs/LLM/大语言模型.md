### 多模态模型

#### CLIP

最开始的多模态模型，是 OpenAI 的多模态模型 CLIP

因为传统文本模型，需要将词映射到语义空间中，即猫狗的词向量接近

而你狗的图片（即使你试图做一些编码）也无法直接加入到这个语义空间

所以 OpenAI 找了 4 亿个高质量图片，配上文本，这是一个 图片-文本 的键值对

通过对键值对进行对比学习，在语义空间做对齐，可以理解为将图片理解为文字

但是，描述图片的文字无法描述所有信息（谁高谁低，谁是什么颜色，有几个，谁大谁小），所以最后导致它识别传统 MNIST 数据集都只有 88 的准确率

它这个学习是双向的，它即能学习到狗图片和狗的相似性，也可以输入狗，找到最相似的图片

#### 无法数清楚 Strawberry 有几个 r

因为大模型是分词，并不是分字母，它的理解局限于 Token 层级，目的是预测下一个 Token，所以没有关注一个 Token 里有几个 r

但是如果你叫它一步步思考，确实可能会成功

就如同 deepseek 说的，Transformer 的“随意注意”为模型提供了全局的、语义的上下文视野，但这双“眼睛”是为瞭望山川、识别物体而生的，而不是用来数清脚下沙子的精确数目

即，Transformer 给了大模型一个可以看到全局的眼睛，但是并不是一个同时处理所有事情的眼睛。就好比人，你虽然能听到附近的所有声音，但是过于微小的（在大模型眼里就是 r 有几个），或者信息太乱，也会忘掉

大模型训练的时候，总是关注附近的词（说是有什么中间遗忘，开头结尾比较好记住），这样分高。导致你和他对话的时候，他虽然看到了，但是还是会忘掉

#### Stable Diffusion 模型

它有三个部分

（1）文本编码器 CLIP。这里直接是 OpenAI 的 CLIP，这样，可以让输入的文字，在语义空间对齐
（2）扩散模型 Diffusion。基本上扩散模型出来以后，就替代了 GAN。扩散模型的目标是对一个噪声图片逐渐去噪，使得它逼近目标。它内部的实现，以前是 UNet，现在是 Transformer，后者称之为 DiT
（3）图像解码器 VAE。类似于超分，减轻中间扩散模型的压力，让它的输出不至于太大

训练时，准备文本-图片对，然后对图片逐步添加噪音，用 Diffusion 学习如何去噪

### 测试清单

HLE：Humanity's Late Exam 人类的最后一次考试，这是一个专门设计的超级困难的问题集合，持续更新

LiveCodeBench：一些难的代码题，持续更新

SWE：工程能力，看大模型能否提交 github 上的一个 pr，通过 test suit

### 命令行 Agent 趋势

Codex 会抢占你的终端，他改的时候你没办法操作，所以目前一个趋势是上云，上沙箱。给它分配几个干净的小型环境，来专门干活

沙箱这个东西你还可以在云服务商那里买到，类似 FaaS，你安装 SDK 后，一行函数，就可构造沙箱，一行函数，就可让沙箱运行 python 脚本

### 训练框架与推理引擎

PyTorch、TensorFlow 训练框架 这个不多说了好吧

TensorRT、ONNX Runtime 通用推理引擎，它是你先在 PyTorch 里训练好了，然后部署到这里，用于生产级别

TensorRT 是 N 卡专用的推理优化引擎，注重极限优化

ONNX Runtime 是微软开发的一个通用引擎，CPU GPU，各种操作系统都能跑，格式为 onnx

vLLM、llama.cpp 大语言模型？

通用引擎它什么架构都能跑，包括 CNN，RNN，Transformer，但是这俩只能跑 Transformer

vLLM 提出了一种叫做 PagedAttention 技术，高效的管理 KV 缓存，一般企业会用。它是借助于 pytorch 或者 ONNX Runtime 来跑，相当于一个框架，而不是引擎（这个我也没用过，不知道具体）

llama.cpp 这个确实是一个引擎，它专注在资源受限设备上跑 LLM，gguf 格式

然后我想到 NVIDIA 的推理卡、训练卡和游戏卡，这东西应该属于是商业上的划分，没有绝对限制

你的笔记本不是一样能本地训练一个 CNN 推理嘛，但是如果你视图去微调 LLM，那不行，因为一个是显存小，再一个是部分卡（推理卡）的 FP32 模块被阉割，只是显存傻大

所以这个 pytorch 这种训练框架，它专注于 前向、反向传播，损失计算，梯度更新等整个流程

而 TensorRT 一般不训练，只推理（有的也能微调，但是不能完整练）

### Skills

现在这个 Claude 把 Skills 的标准公开了，很多工具现在也支持

https://code.claude.com/docs/en/skills

元数据：必定加载（目录），用于降低工具太多导致的 Token 消耗

指令：正文

资源：附录

每个 skill 是一个文件夹（对比 mcp，它是一个可执行程序），包含一个 SKILL.md，此 md 包含了 元数据和指令

然后罗列一大堆子文件夹，每个子文件夹都是资源，资源可以是图片，文本，也可以是脚本

元数据就是 Markdown 的元数据，和我用 hugo 的时候必须填的那个类似，一个 yaml

```yaml
---
name: 复制 XML
discription: 把 runtime 下面的 XML 备份起来
---
```

指令部分其实就是写一个特别详细的提示词，来提示 AI 如何操作。如果你不需要脚本，那么就不需要子文件夹的资源

注意，每次你提问，Claude 会扫描你所有的 SKILL 的元数据，就和工具类似，你只要开启，就直接加入上下文，所以你不用，就不要开

一句话：Skills 是一种提示词管理模式，相当于大号提示词数据库，渐进式的加载提示词。MCP 是一个工具箱，你不要拿太多

这东西我感觉有点傻，但是可能确实有用吧。我认为直接抄别人的 SKILL 是比较好的，不要自己写，但是门槛比较低，这东西执行你 python 的时候，我估计错误处理啥的也是个问题。精准还得是 MCP，但是专用 MCP 非程序员不好写，我看 Cherry Studio 里也提供现成的 MCP

### RVLR

 Recurrent Vector Long-term Retrieval（循环向量长期检索），这是当前增强大型语言模型（LLMs）处理超长上下文能力的一项前沿技术

RMT (Recurrent Memory Transformer)：明确提出了递归记忆令牌的概念，是 RVLR 思想的直接体现

### RLHF
RLHF（Reinforcement Learning from Human Feedback），即基于人类反馈的强化学习，是一套复杂的训练技术，其核心目标是让 AI 模型的行为与人类的价值观和意图对齐

包括遵循指令的能力，也是靠 RLHF

### n8n

[2026-1-19]

这东西去年就开始火，但是我一直没用，今天试了一下

感觉必须是很复杂的项目才需要用这个东西

这东西号称是 no-code，但是实际上，所有的东西都是微服务设计，架构分离，该少的东西你一个不能少（比如你要搭 RAG，那么你一样要部署 Milvus），但是灵活性是够的

这东西应该说是串联起最后的流程，方便产品经理进行调整、调试

比如你做 RAG 产品，你最终的效果好还是不好，那取决于你的 文档解析、数据分块，实际上和 n8n 没啥关系