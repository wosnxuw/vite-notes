# 常见名词解释

### sbert
#### Sentence-BERT

将句子或短文转换成固定长度的向量，这个向量能够很好地捕捉句子的语义信息

SBERT 本身是于 2019 年提出一个方法

不过后续逐渐成为后续模型的训练方法

在它出现之前，像 BERT 这样的模型虽然强大，但直接用于计算句子相似度效率很低

#### 和 BGE-M3 的关系
BGE-M3 采用更先进的预训练模型（如 RoBERTa、ERNIE、DeBERTa）作为基座
 "用 SBERT 做嵌入"在实践中可能就是用 BGE、E5、GTE 等基于相同原理的现代模型

#### 向量长度
对一个给定的具体模型（例如 BGE-M3-zh 或 all-MiniLM-L6-v2）

它输出的所有句子向量长度都是完全相同的固定长度

无论输入句子是 "你好"，还是 "今天天气很好，我打算去公园散步并且晚上看一场电影"

模型都会输出相同维度的向量（例如 768 维或 1024 维）

即：我们需要将所有句子映射到同一个向量空间中

#### 如何做好的嵌入？

1、一份格式化的数据，比如 json、xml
2、只是把最关键数据罗列出来，但是并没有格式化
3、数据尚未整理，比较原始，但是按照语义进行了分段

似乎第 3 种才是最好的

准备数据的关键是创造“语义上自包含”的文本块。

1、
字段名、标点符号等结构性信息会“污染”语义
模型会学习到 "product_name": 和 "price": 这些模式的相似性，而不是产品本身的语义

2、
信息点孤立，缺乏连贯的语义上下文

3、
最接近模型训练时的数据分布

### Token 消耗量

无论是API，还是没有token概念的网页版

多轮对话的消耗都是 **A+2A+3A+...**

每次都会把之前的所有对话内容拼在一起

每次对话请求（包括多轮对话中的每一轮）都是对同一个“无状态”模型的一次独立调用

模型本身没有任何记忆，所谓的“连贯对话”完全依赖于：把之前的对话历史作为文本，重新输入给模型

这就像你每次问一个没有记忆的天才朋友问题，但你每次都把之前的聊天记录打印出来递给他看，他看完后回答你，他看起来“记得”，其实只是“刚读完”

历史记录管理属于上下文工程方面

根本原因：

大语言模型（如 GPT、LLaMA）在部署后，其参数是完全固定的，它的行为可以看作一个确定性函数。（不考虑量化后以及浮点数精度的问题，纯理论上）

没有“会话 ID”、没有“用户档案”、没有“上次聊了什么”的内部变量。

#### 使用函数时的Token消耗量

如果大模型调用外部函数，则Token用量飞速增长

如果我没搞错，一旦调用外部函数，模型就会停止（模型没有运行时实时获取外部函数返回值的功能）

模型给函数传参后，就停下，外部函数算好后，运行一个新的模型实例

虽然各种库给你封装的看起来是一次，但是实际上 Token 消耗很多的

如果你调用 10次 20次 才能解决问题，用量很大，这也可能是为什么，在IDE里这种Agent，来回读你文件夹的它不免费

假设：用户问题消耗为 $A$ 个 token。模型生成的工具调用指令为 $B$ 个 token。外部工具返回的结果为 $C$ 个 token。总消耗情况：第一次推断：消耗 $A$。第二次推断：消耗 $A + B + C$。最终总计：$2A + B + C$。


### 多模态

#### 函数式多模态

其实就是外挂一个函数

本身它还是纯语言模型，你让它画图，它就帮你调用工具

#### 原生多模态

一些强大的模型 GPT 或者 Gemini 之类似乎训练时，已经不只是学习语言了，它也可以直接看懂一个图

你给它一个图，它不需要外挂一个 openCV 程序来识别猫狗，它直接就能识别猫狗

图片对于大模型来说 Token 消耗量很高，视频音频按照秒切分好像是

高清图片重复对话 Token 滚雪球

### 多头注意力

可以把“头”想象成一个委员会中的多个专家

每个专家（头）从自己的专业角度（子空间）分析同一个问题（输入序列），最后大家把意见汇总（拼接+线性变换），做出综合判断。一个头可能关注句法结构，另一个头可能关注语义角色，还有头可能关注局部或长距离依赖。

多头注意力机制本身并不是大模型能处理更长上下文的直接原因，但它为高效建模长距离依赖提供了基础。
真正让大模型能处理更长上下文的，是后续对注意力机制的改进（如稀疏注意力、位置编码优化、计算效率提升等）以及更大的模型规模和训练数据。

标准的Transformer使用的是全注意力（full attention），即每个 token 都要和其他所有 token 计算注意力权重。
因此，早期的Transformer模型（如BERT、GPT-2）通常只支持512或1024个token的上下文。

自注意力机制：可直接建模任意两个 token 之间的关系

每个 token 都能直接关注序列中任意其他 token。

无论距离多远（第1个词和第1000个词），都能建立直接连接。

特别适合理解句子中的主谓一致、指代消解等长程语义。

它用“注意力”替代了“递归”或“卷积”

思考：你说“回到开头”，模型真的会关注开头吗？

