目前这个文章大概是一个新手小白的知识水平，因为我根本没有单反相机。以前都是手机随手搞一下，最近突然想了解一下原理。

初中物理--镜头--计算机图形学，其实是环环相扣的。但是一个是我初中物理只会用公式做题了，根本没有理解。

### 实像和虚像

实像是光线真实交汇后形成的，能用屏幕接到。（可以认为是从真实物体射出）

虚像是光线的反向延长线交汇形成的，只能用眼睛看，无法用屏幕接到。（光线经过透镜后是发散的）

最开始，没有透镜、没有人眼，一个物体发射出的光线（反射的），本身就是发散的。（除了太阳，它相当于平行光线）

如果有了人眼或者透镜，人眼相当于一个凸透镜，可以将物体发出的光线聚焦在视网膜上。

如果用一个凸透镜对着太阳，去灼烧一张纸。此时不涉及人眼，所以光线会汇聚，形成实像。

再复杂的情况就是，人用放大镜阅读文字。此时相当于有两个凸透镜，形成了透镜组合。 

### 凸透镜成像

首先：经过透镜中心点的光线方向不变（对称性）

然后初中物理的口诀是：一倍焦距分虚实，二倍焦距分大小。实像倒立虚像正。

它这个里这个实验图都是一个点燃的蜡烛，因为蜡烛的光比较强，所以能够投射到后面的纸张上。

高斯成像公式：

$$1/f = 1/u + 1/v$$

其中，f 焦距，u 物距，v 像距

根据公式不难看出，一倍分虚实是因为如果物距小于焦距，凸透镜汇聚光线的能力有限，无法再使得其再透镜后方汇聚，所以像距必须是负的。此时也只能再引入人眼这个透镜，来再次汇拢光线，才能看见，屏幕上则无像。

二倍焦距分大小是因为，右边两个分式相等的点恰好是 2f。u > 2f 是缩小，u < 2f 是放大。

举例：

（1）实验里，首次拿放大镜聚焦太阳光时，太阳相当于无穷远，则物距为无穷，所以聚焦后，像距=焦距。（像距是指，凸透镜到成像平面的距离，成像平面可以是纸张，可以是眼睛，可以是 CMOS）比如这里，我们假设焦距是 10cm。

（2）用上述放大镜放大观察蚂蚁时，你必须是距离 5cm 观察蚂蚁才行。这与实际情况是符合的，透镜都是离书本更近，而不是离书本很远。

（3）虽然放大镜的焦距是固定的，但并不意味着，像距和物距都需要固定。当蚂蚁换成蜡烛，就可以在物距>焦距时，在白纸上成像。

### 近视眼

近视眼说明晶状体变厚，焦距变小。那么需要前面放置凹透镜，组成透镜组合，模拟正常人眼。

### 手机镜头

绝大多数手机摄像头都是固定焦距的，此为“定焦镜头”。（相比于“变焦镜头”）

手机摄像头时物距>>二倍焦距，在 CMOS 上成缩小实像。（实际上前面实验不是蜡烛也能成像，只是蜡烛亮，方便肉眼观察，CMOS 灵敏）

手机镜头距离物体的位置不固定，即物距不固定，通过“对焦”，实现获取清晰成像。对焦即调整像距，CMOS 与凸透镜之间的距离，手机内部置有马达，可以调整像距。

目前的主流对焦方式是相位对焦，即 CMOS 里存在特定像素，通过对比左右像素光线是否重合，直接知道远近，进行调整，速度很快。

当手机放大画面时，通常做“数码变焦”，实际上就是裁剪。因为物距固定，焦距固定，想呈清晰的像，那么像距也必须根据对焦后确定。那么你的图片实际上是固定的，放大只是做裁剪。触发放大到 4 倍，才会替换为长焦镜头。

现代手机，如果你有 4 倍长焦，照相 2 倍，实际上是主摄像机 1 倍裁剪 + 结合长焦的部分画面，拼起来的。

以 iPhone 为例，只要是主摄像机拍的，照片上都会显示“24mm”，这就是主摄像机的焦距

### 画幅比例

手机传感器的画幅大多为 4:3，所以，如果你拍照是 16:9 或者 1:1 实际上照相时就开始裁剪了

“查看超取景框取景”，实际上就是取景框里显示主摄的内容，外围用广角镜头拼接一下。如果把缩放调整到 0.5，那么超出的部分就黑了，无法查看了。所以这个操作并不会损失像素。

### 变焦镜头

单反相机的灵活性之一，就是镜头可以替换

它既可以替换其它焦距的定焦镜头，也可以替换变焦镜头

变焦镜头上存在变焦环，通过旋转它，可以改变焦距

因此单反相机+变焦镜头可以实现，在任何时候都进行光学成像，无画质损失，而不是裁剪

### 光圈

单反镜头一般有一个叶片结构，可以控制进光量

而手机镜头一般没有，它的光圈是固定的

光圈的表达式为：

$$f1.8$$

其中 f 为焦距，即光圈孔径的直径，是焦距÷1.8

关键点：f 值（如 1.8）是一个相对光圈，它统一了不同焦距镜头的进光量比例。无论你是 100mm 还是 24mm 的镜头，只要光圈都设置在 f/1.8，那么它们传递到传感器上的单位面积进光量理论上是相同的

以 iPhone 为例，任何摄像头所摄的照片（不管是否放大），查看其焦距和光圈，都是固定的。

 镜头 | 焦距/mm | 相对光圈 | 光圈孔径/mm
---------|----------|---------|--------- 
 主镜头 | 24 | f1.78 | 13.48
 广角镜头 | 13 | f2.2 | 5.91
 长焦镜头 | 100 | f2.8 | 35.71 

So，数字越小，光圈越大。

但是经过计算，我发现一个严重的问题，即长焦镜头的孔径居然达到了 3cm，这明显大于摄像头本身物理结构。

但是实际上手机的焦距也是假的，它是等效焦距，等效在底为全画幅下的焦距，而实际的底极小，实际的焦距大概在 5mm 左右。（因为你想，成实像，你的物距和像距肯定都要大于焦距，你怎么可能在手机里搞出 10cm 的像距呢？）

一般认为人眼的焦距是 40-50mm

### 感光度

目前手机相机通过调整 ISO 和 快门时间 来决定明暗

在夜间，需要提高 ISO，并延长曝光时间，但是提高 ISO 会让画面产生噪点

以 iPhone 为例，查看照片时，下方会显示 ISO50 + 1/331s、ISO500 + 1/33s

### 透视关系

长焦镜头的一个作用是，因为物距有时候离得太远无法调整，像距受制于相机结构，所以只能换更长焦距。

但是如果拍人像，我作为摄影师可以移动的情况下，广角镜头+离人更近，和标准镜头，离人更远，拍出来的人像大小一样。

但是，实际上我们并不能仅考虑人，还要考虑背景，因为背景的物距更大。

此现象一般发生在背景离人很远的时候，比如山脉，远处的建筑。（我拿两个物体实验，把背景物体摆的很远）

如果是长焦，那么远处的背景会被“拉近”，显得很大，你退到很远的地方拍摄。

如果是标准镜头，那么久模拟人眼，远处的背景很小。

如果是广角镜头，一般是商业作品，拍模特，强调艺术性、动作性和立体感才会这样弄。

广角镜头的立体感更强，长焦更扁平一些。

### 景深

你有没有发现我前面说的，我拍摄人，人离我很近，远处的背景离我很远。按理说，一个物距小，一个物距大。而我的镜头焦距固定，像距只能有一个，那么必然会有一个东西是模糊的。为什么最后拍出来，都没有模糊？

是的，其实你人体都不是一个平面，也是有前后立体关系的，物距不一致，为什么还能清晰？

这个和景深有关系。

对焦成功时，物体上一个点，对应成像平面上一个点。

对焦失败时，则对应一个圆，称之为弥散圆。

人眼和 CMOS 的分辨率有限，只要弥散圆的直径够小，就无法分辨了，这就是清晰。

因此能够让像清晰的，物体所在的区间就是景深。

景深和容许弥散圆的直径、焦距、光圈、像距都有关系。

因为光路类似是一个锥体，如果光圈减小，那么锥体更尖，在锥体上裁剪出一个等直径（容许弥散圆的直径）的圆，就需要更长的锥体，那么景深就会变大。

像距同理，像距长，那么锥体变尖，景深变大。

所以在手机主摄上，为什么同时拍人和山脉会清晰。

因为光圈极小，主摄焦距也短，导致景深非常大，都清晰。

人像模式，是通过计算的方式，把背景模糊掉。

焦距越长，它的可视角度越狭窄。这是因为传感器大小固定，你焦距长，那么像距基本上也会跟着涨，那么锥体就会更尖，导致可视角度变窄。如果你定焦，那么可视角度也固定了。

### 手机多摄像头演化

截至 2026 年，较新的手机大概率是广角+标准+长焦的组合。

最早的时候，其中两个摄像头分别照相，通过对比，可以模拟景深的效果，将人物抠出来。现在 AI 强大，随便抠人像。

我还用过那种黑白摄像头，据说目的是提升细节，现在的 CMOS 也不需要这种了。

以 iPhone 为例，其主摄为 1，长焦为 4，那么为什么不在 2 的位置再搞一个摄像头呢？

原因是现在 CMOS 的传感器能做到 4 像素合一，即如果你是 1 倍，那么就把四个像素当作一个（提高处理速度）。如果你开始 2 倍，则不合并，因为面积减小，速度自然提高，也能提高质量。即把主摄的底搞得更强，而不是再弄一个 2 倍。

### 视角

之所以能调整视角，是因为你在物理地移动镜片，改变焦距；或者是你的手机以定焦摄影，然后做了裁剪。裁剪后，视角自然就变小了。

我们都说，长焦镜头视角小，广角镜头视角大。但这是为什么？

这个和之前景深那块所说的圆锥体有关系，不考虑容许弥散圆的情况下（即精准对焦），因为镜头外部（现实世界）实际上有无穷多的东西，360 度环绕。

根据光路可逆，实际上就相当于 CMOS 是四棱锥的底，焦距是高，这样反向往外射出一个四棱锥，即视场。世界是以一个四棱锥的形状被相机“框”进来的。那么焦距变大，视角必然会缩小。

并且这个和景深没关系，就是所谓光圈会导致景深变小。那个时候我们谈的是 CMOS 上的一个单一的像素，是如何受到外界所有物体反射的光的叠加影响。这个点通过镜头中心，向现实世界投射出一条主光线。这条线决定了这个像素点正对着世界的哪个方向。同时，它需要接收一定角度范围内的光线才能正常成像，这个圆锥形的光锥就是如何去看世界。

### 计算机图形学

在计算机图形学里，类似于小孔成像

景深 = 无穷，不需要对焦

图形学摄像机保留了“焦距”的概念，但把它转化为了一个纯粹的数学参数——视场角。（FOV，Field of View）

在图形学世界里，直接控制“视锥体”的张开角度。

图形学摄像机位于一个点，它向外发射出一个四棱锥（平头截体）。这个锥体的尖端是摄像机，锥体展开的部分就是你能看到的范围。

我们之前谈到景深，之所以现实世界里有景深，是因为现实世界光路复杂，物体上一个点，发出无数条光线，经过类似于圆锥体形状汇聚到 CMOS 上一个点。它是用 CMOS 裁剪了这个圆锥。你的光圈越大，圆锥越胖，景深越小。那么可以想象到，你的光圈如果极小，是一个点，其实景深就无限了，但是在现实世界无法透过光。

景深的物理根源是有限大小的光圈。（导致了光线角度分散）

然而在非光追图像学里，是针孔相机模型，相当于光圈直径为 0 但还能透光，所以物体上发出的一个光，只能有一条光线经过光圈，自然景深也就无限了。因为你底离得多远，都无所谓了，反正就一条光线。

宽视角（广角，120 fov）：让这个锥体的顶角变大。这意味着摄像机张开大口，捕捉更多两侧的世界。这对应着物理世界中的短焦距。

窄视角（长焦，90 fov）：让这个锥体的顶角变小。这意味着摄像机眯起眼睛，只盯着远处很小的一块区域，然后把这块区域放大到整个屏幕上。这对应着物理世界中的长焦距。

我思考到计算机世界的透视投影和正交投影。

实际上正交投影就是焦距无穷大。

透视投影的话，由于 fov 和底的像素已经确定，那么实际上也有一个虚拟焦距。

### 近大远小

什么是近大远小？

在画室，你会把离你近的边画的更长。但是这就是近大远小吗？

其实，大是指，这个东西，在你的视场里，它所占的视角更大。

类似三角函数，离得近，如果是 tan 也会变大嘛。

焦距决定了这个“小”的程度被如何记录和呈现。

所谓希区柯克变焦，你对着正方体做，那不就是畸变程度逐渐变化的过程嘛？

正交投影，正常情况下，就是等长的对应等长。之所以我总感觉“近小远大”，实际上是大脑用透视经验去解读非透视图像时产生的认知偏差。

产生“近大远小”透视关系的根本原因，即物距。既然透视是由“距离”决定的，广角镜头的焦距更短，物距更短，所以才造成近大远小。

在几何学上，当光源或观察点移动到无限远处时，原本呈放射状的视线（投影线）就会变成完全平行的直线

### 名词

单反：数码单镜头反光相机

微单：无反光镜可换镜头相机

单反相机里面有一面镜子，微单相机里面没有这面镜子。光线进来以后，会将画面矫正为正常画面。而微单是直接给颠倒画面，通过计算来矫正。

基本上现在都是微单，就是镜头拿下来后，直接露出 CMOS 那种，单反已经基本上不发展了。少数专业领域用。

单反相机更厚，然后头上有一个五棱镜突起。

全画幅：全画幅指的是相机内部图像传感器的物理尺寸，它传统上与 35mm 胶片（36mm × 24mm）的成像面积完全相同。

APS-C 画幅：约 24mm × 16mm，消费级常见。

潜望式：其实就是手机长焦不够厚，那么就纵向搞，换个走向。